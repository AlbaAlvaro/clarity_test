{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new session on Spark\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ClarityAI_test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file provided\n",
    "\n",
    "df = spark.read.text(r\"C:\\Users\\34676\\Desktop\\prueba_tecnica_clarityAI\\input-file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe only contains one column with all the data, but we need to have the timestamp,the first host and the second host in separate columns so that we can later select the columns with an sql query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating three columns with the data separated so that we can work with it later\n",
    "\n",
    "df1 = df.withColumn('timestamp', split(df['value'], ' ').getItem(0)) \\\n",
    "       .withColumn('from', split(df['value'], ' ').getItem(1))\\\n",
    "       .withColumn('to', split(df['value'], ' ').getItem(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------+-----------+--------+\n",
      "|value                           |timestamp    |from       |to      |\n",
      "+--------------------------------+-------------+-----------+--------+\n",
      "|1565647204351 Aadvik Matina     |1565647204351|Aadvik     |Matina  |\n",
      "|1565647205599 Keimy Dmetri      |1565647205599|Keimy      |Dmetri  |\n",
      "|1565647212986 Tyreonna Rehgan   |1565647212986|Tyreonna   |Rehgan  |\n",
      "|1565647228897 Heera Eron        |1565647228897|Heera      |Eron    |\n",
      "|1565647246869 Jeremyah Morrigan |1565647246869|Jeremyah   |Morrigan|\n",
      "|1565647247170 Khiem Tailee      |1565647247170|Khiem      |Tailee  |\n",
      "|1565647256008 Remiel Jadon      |1565647256008|Remiel     |Jadon   |\n",
      "|1565647260788 Monet Jarreth     |1565647260788|Monet      |Jarreth |\n",
      "|1565647264445 Jil Cerena        |1565647264445|Jil        |Cerena  |\n",
      "|1565647268712 Naetochukwu Kallan|1565647268712|Naetochukwu|Kallan  |\n",
      "|1565647289553 Jahmani Markena   |1565647289553|Jahmani    |Markena |\n",
      "|1565647300338 Davie Nafeesa     |1565647300338|Davie      |Nafeesa |\n",
      "|1565647303287 Antwine Grantham  |1565647303287|Antwine    |Grantham|\n",
      "|1565647309932 Nyiasia Zoeylynn  |1565647309932|Nyiasia    |Zoeylynn|\n",
      "|1565647313867 Kishauna Liem     |1565647313867|Kishauna   |Liem    |\n",
      "|1565647318266 Cante Alsatia     |1565647318266|Cante      |Alsatia |\n",
      "|1565647328946 Fyodor Anudeep    |1565647328946|Fyodor     |Anudeep |\n",
      "|1565647363038 Isabelle Suzu     |1565647363038|Isabelle   |Suzu    |\n",
      "|1565647368307 Mehkai Alyaa      |1565647368307|Mehkai     |Alyaa   |\n",
      "|1565647375948 Jackhenry Mystee  |1565647375948|Jackhenry  |Mystee  |\n",
      "+--------------------------------+-------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a temporary table that stores the data we are going to retrieve with the sql query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a temporary table\n",
    "\n",
    "df1.registerTempTable(\"Logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+--------+\n",
      "|               value|    timestamp|       from|      to|\n",
      "+--------------------+-------------+-----------+--------+\n",
      "|1565647204351 Aad...|1565647204351|     Aadvik|  Matina|\n",
      "|1565647205599 Kei...|1565647205599|      Keimy|  Dmetri|\n",
      "|1565647212986 Tyr...|1565647212986|   Tyreonna|  Rehgan|\n",
      "|1565647228897 Hee...|1565647228897|      Heera|    Eron|\n",
      "|1565647246869 Jer...|1565647246869|   Jeremyah|Morrigan|\n",
      "|1565647247170 Khi...|1565647247170|      Khiem|  Tailee|\n",
      "|1565647256008 Rem...|1565647256008|     Remiel|   Jadon|\n",
      "|1565647260788 Mon...|1565647260788|      Monet| Jarreth|\n",
      "|1565647264445 Jil...|1565647264445|        Jil|  Cerena|\n",
      "|1565647268712 Nae...|1565647268712|Naetochukwu|  Kallan|\n",
      "|1565647289553 Jah...|1565647289553|    Jahmani| Markena|\n",
      "|1565647300338 Dav...|1565647300338|      Davie| Nafeesa|\n",
      "|1565647303287 Ant...|1565647303287|    Antwine|Grantham|\n",
      "|1565647309932 Nyi...|1565647309932|    Nyiasia|Zoeylynn|\n",
      "|1565647313867 Kis...|1565647313867|   Kishauna|    Liem|\n",
      "|1565647318266 Can...|1565647318266|      Cante| Alsatia|\n",
      "|1565647328946 Fyo...|1565647328946|     Fyodor| Anudeep|\n",
      "|1565647363038 Isa...|1565647363038|   Isabelle|    Suzu|\n",
      "|1565647368307 Meh...|1565647368307|     Mehkai|   Alyaa|\n",
      "|1565647375948 Jac...|1565647375948|  Jackhenry|  Mystee|\n",
      "+--------------------+-------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Proving the temporary table has been created correctly\n",
    "\n",
    "spark.sql(\"SELECT * FROM Logs\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I tried passing the data to the query manually, so that I could test if it worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|    timestamp|    from|\n",
      "+-------------+--------+\n",
      "|1565647368307|  Mehkai|\n",
      "|1565650799255|  Donnis|\n",
      "|1565663573006|  Careli|\n",
      "|1565685686037| Irielle|\n",
      "|1565697613185| Mugilan|\n",
      "|1565711104391|  Nyarai|\n",
      "|1565715430365|Adreyona|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = {\"init_datetime\":1565647204351,\n",
    "           \"end_datetime\":1565647204352,\n",
    "           \"to_host\":'Alyaa'}\n",
    "\n",
    "Q1 = spark.sql(\"\"\"SELECT timestamp, from FROM Logs \n",
    "                  WHERE timestamp>{init_datetime} AND timestamp>{end_datetime} AND to='{to_host}'\n",
    "               \"\"\".format(**configs)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had tested that the query worked well I passed the data to the query with the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write an initial time: 1565647368307\n"
     ]
    }
   ],
   "source": [
    "init_datetime=input(\"Write an initial time: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a final time: 1565650799255\n"
     ]
    }
   ],
   "source": [
    "end_datetime=input(\"Write a final time: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a host: Alyaa\n"
     ]
    }
   ],
   "source": [
    "to_host=input(\"Write a host: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|    timestamp|    from|\n",
      "+-------------+--------+\n",
      "|1565663573006|  Careli|\n",
      "|1565685686037| Irielle|\n",
      "|1565697613185| Mugilan|\n",
      "|1565711104391|  Nyarai|\n",
      "|1565715430365|Adreyona|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = {\"init_datetime\":init_datetime,\n",
    "           \"end_datetime\":end_datetime,\n",
    "           \"to_host\":to_host}\n",
    "Q1 = spark.sql(\"\"\"SELECT timestamp, from FROM Logs \n",
    "                  WHERE timestamp>{init_datetime} AND timestamp>{end_datetime} AND to='{to_host}'\n",
    "               \"\"\".format(**configs)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query returns a list of hostnames connected to the host, in this example Alyaa, in between the inicial and the end given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col, hour, minute, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried to define a function that gets the hours from timestamp format and creates a file each hour.\n",
    "\n",
    "def hourly():\n",
    "    df = spark.read.text(r\"C:\\Users\\34676\\Desktop\\prueba_tecnica_clarityAI\\input-file.txt\", \"r\")\n",
    "    df1 = df.withColumn('timestamp', split(df['value'], ' ').getItem(0)) \\\n",
    "       .withColumn('from', split(df['value'], ' ').getItem(1))\\\n",
    "       .withColumn('to', split(df['value'], ' ').getItem(2))\n",
    "    data = df1.select(\"timestamp\")\n",
    "    d = datetime.strptime(data, '%Y-%m-%d %H:%M:%S')\n",
    "    df3['hour'] = d.hour\n",
    "    if data==0:\n",
    "        print(data)\n",
    "        \n",
    "        \n",
    "hourly()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------+--------+\n",
      "|               value|timestamp|       from|      to|\n",
      "+--------------------+---------+-----------+--------+\n",
      "|1565647204351 Aad...|     null|     Aadvik|  Matina|\n",
      "|1565647205599 Kei...|     null|      Keimy|  Dmetri|\n",
      "|1565647212986 Tyr...|     null|   Tyreonna|  Rehgan|\n",
      "|1565647228897 Hee...|     null|      Heera|    Eron|\n",
      "|1565647246869 Jer...|     null|   Jeremyah|Morrigan|\n",
      "|1565647247170 Khi...|     null|      Khiem|  Tailee|\n",
      "|1565647256008 Rem...|     null|     Remiel|   Jadon|\n",
      "|1565647260788 Mon...|     null|      Monet| Jarreth|\n",
      "|1565647264445 Jil...|     null|        Jil|  Cerena|\n",
      "|1565647268712 Nae...|     null|Naetochukwu|  Kallan|\n",
      "|1565647289553 Jah...|     null|    Jahmani| Markena|\n",
      "|1565647300338 Dav...|     null|      Davie| Nafeesa|\n",
      "|1565647303287 Ant...|     null|    Antwine|Grantham|\n",
      "|1565647309932 Nyi...|     null|    Nyiasia|Zoeylynn|\n",
      "|1565647313867 Kis...|     null|   Kishauna|    Liem|\n",
      "|1565647318266 Can...|     null|      Cante| Alsatia|\n",
      "|1565647328946 Fyo...|     null|     Fyodor| Anudeep|\n",
      "|1565647363038 Isa...|     null|   Isabelle|    Suzu|\n",
      "|1565647368307 Meh...|     null|     Mehkai|   Alyaa|\n",
      "|1565647375948 Jac...|     null|  Jackhenry|  Mystee|\n",
      "+--------------------+---------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I was trying to get the hours from the timestamp column\n",
    "\n",
    "df1.withColumn(\"timestamp\",hour(col(\"timestamp\"))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
